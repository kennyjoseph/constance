{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ujson as json\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "from copy import copy\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.matutils import corpus2dense\n",
    "from twitter_dm.nlp.Tokenize import extract_tokens_twokenize_and_regex as do_tokenize\n",
    "import os\n",
    "from datetime import datetime \n",
    "from collections import Counter\n",
    "from vaderSentiment.vaderSentiment import sentiment\n",
    "import numpy as np \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import io\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from numpy.random import choice\n",
    "\n",
    "np.set_printoptions(threshold=10000,\n",
    "                    linewidth=100,\n",
    "                    formatter={'float_kind':lambda x: \"%.8f\" % x })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 22)\n",
      "(10609, 24)\n"
     ]
    }
   ],
   "source": [
    "train_tweets = pd.read_csv(\"./data/annotation_results_full.csv\",dtype={\"tid\":\"str\"})\n",
    "test_tweets = pd.read_csv(\"./data/test_tweets.csv\",dtype={\"tid\":\"str\"})\n",
    "print test_tweets.shape\n",
    "print train_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure candidate interaction columns are the same for training and test\n",
    "tweet_info = pd.concat((train_tweets[~train_tweets.tid.duplicated()],test_tweets),axis=0)\n",
    "tweet_info.loc[tweet_info.candidate_interaction == \"NONE\",\"candidate_interaction\"] = \"No Mention of Target\"\n",
    "tweet_info.loc[tweet_info.candidate_interaction == \"TextMention\",\n",
    "                                                        \"candidate_interaction\"] = \"Plaintext Mention\"\n",
    "\n",
    "# Add feature as to whether or not the tweet had a link\n",
    "tweet_info['has_link'] = tweet_info.tweet_text.apply(lambda x: '{{link}}' in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_user_features(uids_to_featurize,user_to_tid,tweet_info):\n",
    "    \n",
    "    # clean user features, add political party\n",
    "    user_features = pd.DataFrame(user_to_tid.items(),columns=['uid','tid'])\n",
    "    user_features['uid'] = user_features.uid.astype(int)\n",
    "    user_affil = pd.get_dummies(tweet_info[['tid','voter_pol_affil']], prefix='pol', columns=['voter_pol_affil'],drop_first=True)\n",
    "    tweet_info['voter_race'] = tweet_info.voter_ethnicity.map({\"B\":\"B\",\"H\":\"H\",\"N\":\"O\",\"O\":\"O\",\"U\":\"O\",\"W\":\"0_White\",\"A\":\"A\"})\n",
    "    user_race = pd.get_dummies(tweet_info[['tid','voter_race']], prefix='race', columns=['voter_race'],drop_first=True)\n",
    "    user_gender = pd.get_dummies(tweet_info[['tid','voter_gender']], prefix='gend', columns=['voter_gender'],drop_first=True)\n",
    "    user_features = pd.merge(user_features,user_affil,on=\"tid\")\n",
    "    user_features = pd.merge(user_features,user_race,on=\"tid\")\n",
    "    user_features = pd.merge(user_features,user_gender,on=\"tid\")\n",
    "    print user_features.shape\n",
    "    return user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 9)\n"
     ]
    }
   ],
   "source": [
    "uids_to_featurize = train_tweets.uid.unique().tolist() + test_tweets.uid.unique().tolist()\n",
    "user_to_tid = {}\n",
    "for i, row in train_tweets.iterrows():\n",
    "    user_to_tid[row['uid']] = row['tid']\n",
    "for i, row in test_tweets.iterrows():\n",
    "    user_to_tid[row['uid']] = row['tid']\n",
    "    \n",
    "user_features = get_user_features(uids_to_featurize,user_to_tid,tweet_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get tweet features\n",
    "TERM_SEP = \"\\n\\n\\n#####$$$$$\\n\\n\\n#####$$$$$\"\n",
    "stopwords = {\"{{\",\"}}\",\"...\", '', '\"\"', \"a\",\"and\",\"the\"}\n",
    "sent_names = ['e_tot','p_tot','a_tot','has_link','tot_sent']\n",
    "def featurize_particular_tweet_set(tweet_data,sent_words,sent_values,n_below=5,dictionary=None):\n",
    "    tweet_texts = []\n",
    "    sent_features = []\n",
    "    for k, v in tweet_data.iterrows():\n",
    "\n",
    "        # Create bag of words from all tweets seen by annotators\n",
    "        tokens = []\n",
    "        char_ngrams = []\n",
    "        for tok_set in v[\"all_text\"].split(TERM_SEP):\n",
    "            tokens += do_tokenize(tok_set,stopwords,do_arabic_stemming=False,gram_list=[2,3])\n",
    "            ng_tok = do_tokenize(tok_set,stopwords,do_arabic_stemming=False)\n",
    "            for k in [3,4,5]:\n",
    "                for tok in ng_tok:\n",
    "                    char_ngrams += [tok[i:i+k] for i in range(len(tok)-k-1)]\n",
    "        tokens += char_ngrams\n",
    "        tweet_texts.append(tokens)\n",
    "        \n",
    "        # Create sentiment features from single tweet, b/c we have target info\n",
    "        single_tweet_tokens = do_tokenize(v['tweet_text'],stopwords,do_arabic_stemming=False)\n",
    "        sent_arr_tweet = np.array([sent_values[word] for word in set(single_tweet_tokens) & sent_words])\n",
    "        sent_tot = sentiment(v['tweet_text'])['compound']\n",
    "        if len(sent_arr_tweet):\n",
    "            sent_feats = (sent_arr_tweet.sum(axis=0)/len(single_tweet_tokens)).tolist()\n",
    "            if v['candidate'] == 'Donald Trump':\n",
    "                sent_feats = [-1*x for x in sent_feats]\n",
    "        else:\n",
    "            sent_feats = [0] * (len(sent_names)-2)\n",
    "        sent_features.append(sent_feats + [v['has_link'], sent_tot])\n",
    "\n",
    "\n",
    "    if not dictionary:\n",
    "        dictionary = corpora.Dictionary(tweet_texts)\n",
    "        # get rid of words appearing < K times (K == 10)\n",
    "        dictionary.filter_extremes(no_below=n_below)\n",
    "        dictionary.compactify()\n",
    "    \n",
    "    # score using IDF\n",
    "    tfidf = models.TfidfModel([dictionary.doc2bow(text) for text in tweet_texts])\n",
    "    text_mat = corpus2dense([tfidf[dictionary.doc2bow(text)] for text in tweet_texts],num_terms=len(dictionary)).T\n",
    "    return text_mat, np.array(sent_features), dictionary\n",
    "\n",
    "def get_tweet_features(tweet_info,\n",
    "                       dictionary_tweet=None,\n",
    "                       dictionary_pol=None,\n",
    "                       dictionary_prev=None):\n",
    "    sent_values = {}\n",
    "    sent_words = set()\n",
    "    for x in io.open(\"data/clean_epa_terms.txt\"):\n",
    "        x_spl = x.split(\"\\t\")\n",
    "        word = x_spl[0]\n",
    "        sent_values[word] = [float(x_spl[1]),float(x_spl[2]),float(x_spl[3])]\n",
    "        sent_words.add(word)\n",
    "        \n",
    "    tweet_info['description'] = tweet_info.description.fillna(\"\")\n",
    "    tweet_info['all_text'] = tweet_info.apply(lambda x : TERM_SEP.join([x['prev1'],x['prev2'],\n",
    "                                                              x['pol_prev1'],x['pol_prev2'],\n",
    "                                                              x['tweet_text'],\n",
    "                                                              x['description'].decode(\"utf8\")]),axis=1)\n",
    "    # Get features \n",
    "    (word_features_tweet, \n",
    "     sent_features_tweet, \n",
    "     dictionary_tweet) = featurize_particular_tweet_set(tweet_info,sent_words,sent_values,10,dictionary_tweet)\n",
    "\n",
    "    # Concat w/ candidate interaction features\n",
    "    tweet_features = np.concatenate((word_features_tweet, sent_features_tweet,\n",
    "                                 pd.get_dummies(tweet_info.candidate_interaction,drop_first=True).values),axis=1)\n",
    "\n",
    "    # get column names\n",
    "    colnames = []\n",
    "    all_token_features = []\n",
    "    ordered_tokens = [dictionary_tweet[i] for i in range(len(dictionary_tweet))]\n",
    "    colnames += ['t_'+x for x in ordered_tokens] + sent_names\n",
    "    colnames += pd.get_dummies(tweet_info.candidate_interaction,drop_first=True).columns.tolist()\n",
    "\n",
    "    # tack on uid and tid\n",
    "    tweet_features = pd.DataFrame(tweet_features, columns=colnames)\n",
    "    tweet_features['tid'] = tweet_info.tid.tolist()\n",
    "    tweet_features['uid'] = tweet_info.uid.tolist()\n",
    "\n",
    "    return tweet_features, dictionary_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_features,dictionary_tweet = get_tweet_features(tweet_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pd.merge(tweet_features,user_features,on=\"tid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_features = tweet_features.columns.tolist()[:-2]\n",
    "user_features = ['race_A','race_B','race_H','race_O','gend_M','gend_U']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = tweet_features + user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_map = {-1 : \"Trump\", 1 : \"Clinton\", 0 : \"A_None\"}\n",
    "y_list = ['A_None','Clinton','Trump']\n",
    "\n",
    "def my_mode(x):\n",
    "    c_res = Counter(x).most_common()\n",
    "    maxv = c_res[0][1]\n",
    "    vals = [c_res[0][0]]\n",
    "    for x in c_res[1:]:\n",
    "        if x[1] == maxv:\n",
    "            vals.append(x[0])\n",
    "        else:\n",
    "            break\n",
    "    if len(vals) == 1:\n",
    "        return vals[0]\n",
    "    else:\n",
    "        try:\n",
    "            vals.remove(0)\n",
    "        except:\n",
    "            pass\n",
    "        if len(vals) == 1:\n",
    "            return vals[0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "        \n",
    "def set_annotations_array_indices(data, candidate):\n",
    "    df = pd.DataFrame([x-1 for x in data],columns=['final annotation'])\n",
    "    df['candidate'] = candidate\n",
    "    return set_annotations(df)\n",
    "\n",
    "def set_annotations(data,field='final annotation'):\n",
    "    annotations = [x[field] if x['candidate'] == 'Hillary Clinton' else x[field]*-1 for i,x in data.iterrows()]\n",
    "    return [y_map[x] for x in annotations]\n",
    "\n",
    "def get_annotation_index(a):\n",
    "    if a == 'A_None':\n",
    "        return 0\n",
    "    if a == 'Clinton':\n",
    "        return 1\n",
    "    if a == 'Trump':\n",
    "        return 2\n",
    "    return -1000\n",
    "\n",
    "def get_pred_from_index(a):\n",
    "    if a == 1:\n",
    "        return 1\n",
    "    elif a == 2:\n",
    "        return -1\n",
    "    return a\n",
    "\n",
    "def get_evaluations(testY, testX, model):\n",
    "    preds = model.predict(testX)\n",
    "    prob_a_preds = model.predict_proba(testX)    \n",
    "    no_avg = metrics.f1_score(testY, preds,average=None)\n",
    "    print no_avg\n",
    "    return { \"ll\" : metrics.log_loss(testY, prob_a_preds ,labels=['A_None','Clinton','Trump']),\n",
    "             \"f1_clint\" : no_avg[1],\n",
    "             \"f1_trump\" : no_avg[2],\n",
    "             \"f1_avg\": (no_avg[1]+no_avg[2])/2.,\n",
    "             \"predictions\": preds,\n",
    "             \"probabilities\": prob_a_preds\n",
    "           }\n",
    "\n",
    "def get_from_sampling(train_tweet_ann, features, feature_cols,n=5):\n",
    "    df = (train_tweet_ann.groupby(['tid','trinary']).uid\n",
    "          .count()\n",
    "          .reset_index()\n",
    "          .pivot(\"tid\",\"trinary\",\"uid\")\n",
    "          .fillna(0)\n",
    "          .reset_index())\n",
    "\n",
    "    df.columns = ['tid','-1','0','1']\n",
    "    df = pd.merge(df,features,on=\"tid\")\n",
    "    df = pd.merge(df, train_tweet_ann[['tid','candidate']].drop_duplicates(),how='left')\n",
    "    print 'df shape: ', df.shape\n",
    "    ys = []\n",
    "    obs = []\n",
    "    for i, x in df.iterrows():\n",
    "        # set y_i\n",
    "        prob_values = (x.loc[['-1','0','1']].astype(float).values / \n",
    "                       x.loc[['-1','0','1']].astype(float).values.sum())\n",
    "\n",
    "        ys += set_annotations_array_indices(\n",
    "                np.random.choice(3,size=n,p=prob_values.tolist()),\n",
    "                x['candidate'])\n",
    "        #print prob_values, ys[-1], x['candidate']\n",
    "        obs += [x[feature_cols].tolist()] * n\n",
    "    y = np.array(ys)\n",
    "    X = np.array(obs)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Vote Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_majority_vote_models(context,\n",
    "                             train_tweets,\n",
    "                             test_tweets,\n",
    "                             features,\n",
    "                             feature_cols,\n",
    "                             feature_cols_type=\"\",\n",
    "                             do_sampling=False,\n",
    "                             add_manual=False,\n",
    "                             max_depth=15,\n",
    "                             n_estimators=2000,\n",
    "                             n_to_sample=5,\n",
    "                             class_weights=None,\n",
    "                             return_classifier=False):\n",
    "    \n",
    "    print context\n",
    "    \n",
    "    # pick tweets based on context\n",
    "    if context == 'All':\n",
    "        train_tweet_ann = train_tweets\n",
    "    else:\n",
    "        train_tweet_ann = train_tweets[train_tweets.context == context]\n",
    "    \n",
    "    # get modal agreement score / gold standard label\n",
    "    if do_sampling:\n",
    "        train_tweet_annotations = train_tweet_ann\n",
    "    else:\n",
    "        train_tweet_annotations = (train_tweet_ann\n",
    "                                   .groupby(['tid','uid','candidate'])\n",
    "                                   .trinary.apply(my_mode)\n",
    "                                   .reset_index())\n",
    "    train_tweet_annotations.loc[:,'final annotation'] = train_tweet_annotations.trinary\n",
    "    \n",
    "    # merge in features\n",
    "    train_annotations = pd.merge(train_tweet_annotations,features,on=\"tid\")\n",
    "    \n",
    "    # construct test data\n",
    "    test_annotations = pd.merge(test_tweets,features,on=\"tid\")\n",
    "    testX = test_annotations[feature_cols]\n",
    "    testY = set_annotations(test_annotations)\n",
    "    \n",
    "    # Run model\n",
    "    if do_sampling:\n",
    "        X, y = get_from_sampling(train_tweet_ann, features, features,n_to_sample)\n",
    "    else:\n",
    "        y = set_annotations(train_annotations)\n",
    "        X = train_annotations[feature_cols]\n",
    "        \n",
    "        \n",
    "       \n",
    "    if class_weights == \"OUR_AUTO\":\n",
    "        y_labs = Counter(y)\n",
    "        test_labs = Counter(testY)\n",
    "        class_weights = {k : float(test_labs[k])/y_labs[k] for k in y_list}\n",
    "    \n",
    "    classifier=RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators,\n",
    "                                     class_weight=class_weights)\n",
    "\n",
    "    \n",
    "    res = classifier.fit(X,y)\n",
    "    evals = get_evaluations(testY,testX, res)\n",
    "\n",
    "    ret_v = evals.values() + [context, feature_cols_type,do_sampling,\n",
    "            add_manual,max_depth,n_estimators,\n",
    "            str(class_weights[\"Clinton\"])+\"_\"+str(class_weights[\"A_None\"]) if class_weights else 1,res,\n",
    "            Counter(res.predict(testX)), evals.keys()]\n",
    "    if not return_classifier:\n",
    "        return ret_v\n",
    "    else:\n",
    "        return ret_v + [classifier]\n",
    "    \n",
    "def run_func_majority_vote(x):\n",
    "    return run_majority_vote_models(train_tweets=train_tweets,\n",
    "                                     test_tweets=test_tweets,\n",
    "                                     features=features,\n",
    "                                     do_sampling=False,\n",
    "                                     n_to_sample=5,\n",
    "                                     **x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    out = e_x / e_x.sum()\n",
    "    return out\n",
    "\n",
    "# Compute LL\n",
    "def compute_loglikelihood(alphas,gammas,classifier_predictions,\n",
    "                          tweet_to_context_to_annotations_map,n_contexts):\n",
    "    log_likelihood = 0\n",
    "    for tw_it in range(N_TWEETS):\n",
    "        # for each possible \"true\" tweet lable\n",
    "        y_sum = 0\n",
    "        for y_it in range(N_QUESTION_ANSWERS):\n",
    "            # for each context\n",
    "            m_prod = 1\n",
    "            for m_it in range(n_contexts):\n",
    "                s_sum = 0\n",
    "                # for each possible \"true\" context value\n",
    "                for s_it in range(N_QUESTION_ANSWERS):\n",
    "                    # for each annotation\n",
    "                    ann_v = 1\n",
    "                    for ann_id, ann, conf in tweet_to_context_to_annotations_map[tw_it][m_it]:\n",
    "                        ann_v *= alphas[ann_id,s_it,ann] * conf\n",
    "                    s_sum += gammas[m_it,y_it,s_it] * ann_v\n",
    "                m_prod *= s_sum\n",
    "            y_sum += m_prod*classifier_predictions[tw_it,y_it]\n",
    "        log_likelihood += np.log(y_sum)\n",
    "    return log_likelihood\n",
    "\n",
    "    \n",
    "def get_p_s_im_a(y_it, alphas, gammas, context_to_annotations_map,n_contexts):\n",
    "    p_s_im_a = np.zeros((n_contexts,N_QUESTION_ANSWERS))\n",
    "    for m_it in range(n_contexts):\n",
    "        for s_it in range(N_QUESTION_ANSWERS):\n",
    "            # probability of s_im\n",
    "            p_s_given_y_gamma = gammas[m_it,y_it,s_it]\n",
    "            # p(y_im for all j | s_im, alpha)\n",
    "            p_yj_given_s_alpha = 1\n",
    "            for ann_id, ann, conf in context_to_annotations_map[m_it]:\n",
    "                p_yj_given_s_alpha *= alphas[ann_id,s_it,ann] *conf\n",
    "                \n",
    "            # set the value for this expectation\n",
    "            p_s_im_a[m_it,s_it] = (p_s_given_y_gamma * p_yj_given_s_alpha)\n",
    "    return p_s_im_a\n",
    "\n",
    "def e_step(classifier_predictions,alphas,gammas,y_prior,tweet_to_context_to_annotations_map,n_contexts):\n",
    "    \n",
    "    prob_latent = np.zeros((N_TWEETS,N_QUESTION_ANSWERS) + tuple([N_QUESTION_ANSWERS]*n_contexts))\n",
    "\n",
    "    # for each tweet\n",
    "    for tw_it in range(N_TWEETS):\n",
    "        # for each possible \"true\" tweet label\n",
    "        for y_it in range(N_QUESTION_ANSWERS):\n",
    "            # get the classifier probability\n",
    "            p_y_given_x_w = classifier_predictions[tw_it, y_it]\n",
    "            \n",
    "            prob_mat = np.zeros(tuple([N_QUESTION_ANSWERS]*n_contexts))\n",
    "            p_s_im_a = get_p_s_im_a(y_it, alphas, gammas, tweet_to_context_to_annotations_map[tw_it],n_contexts)\n",
    "            for index, x in np.ndenumerate(prob_mat):\n",
    "                prob_mat[index] = np.sum(np.log([ p_s_im_a[v_ind,val] for v_ind,val in enumerate(index)]))\n",
    "                \n",
    "                \n",
    "                \n",
    "            # normalize the expectation over possible combinations of y_i, s_im\n",
    "            prob_latent[tw_it,y_it] = np.log(p_y_given_x_w) + prob_mat + np.log(y_prior[y_it])\n",
    "        prob_latent[tw_it] -= np.log(np.exp(prob_latent[tw_it]).sum())\n",
    "        prob_latent[tw_it] = np.exp(prob_latent[tw_it]) \n",
    "    return prob_latent\n",
    "\n",
    "def construct_marginals_over_latent_for_alpha(prob_latent,n_contexts):\n",
    "    marginals = np.zeros((N_TWEETS,n_contexts,N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))\n",
    "    for tw_it in range(N_TWEETS):\n",
    "        for m_it in range(n_contexts):\n",
    "            for y_it in range(N_QUESTION_ANSWERS):\n",
    "                marginals[tw_it,m_it,y_it,:] = prob_latent[tw_it,y_it].sum(axis=tuple([i for i in range(n_contexts) if i != m_it]))\n",
    "    return marginals\n",
    "\n",
    "def m_step_alpha(prob_latent,annotator_to_annotations_map,n_contexts,n_annotators,alpha_prior):\n",
    "    alphas = np.zeros((n_annotators,N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))\n",
    "    marginals = construct_marginals_over_latent_for_alpha(prob_latent,n_contexts)\n",
    "    # update alphas\n",
    "    # for each annotator\n",
    "    for ann_it in range(n_annotators):\n",
    "        # get all of their annotations\n",
    "        annotations = annotator_to_annotations_map[ann_it]\n",
    "\n",
    "        for cell_s_it in range(N_QUESTION_ANSWERS):\n",
    "            for cell_q_it in range(N_QUESTION_ANSWERS):\n",
    "                numerator = 0\n",
    "                denominator = 0\n",
    "\n",
    "                # calculate their \"expected\" answer for each annotation\n",
    "                for ann_tweet, ann_context, ann_value, ann_conf in annotations:\n",
    "                    # sum over all possible y\n",
    "                    for y_it in range(N_QUESTION_ANSWERS):  \n",
    "                        v = marginals[ann_tweet,ann_context, y_it, cell_s_it]\n",
    "                        if ann_value == cell_q_it:\n",
    "                            numerator += v\n",
    "                        denominator += v\n",
    "\n",
    "                # set their alpha for this combination\n",
    "                #print numerator, denominator\n",
    "                numerator +=  alpha_prior[cell_s_it,cell_q_it]\n",
    "                alphas[ann_it,cell_s_it,cell_q_it] = float(numerator) / (denominator + alpha_prior[cell_s_it,:].sum())\n",
    "    return alphas\n",
    "                \n",
    "                \n",
    "                \n",
    "def m_step_gamma(prob_latent,n_contexts,gamma_prior):\n",
    "    gammas = np.zeros((n_contexts,N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)) \n",
    "    # update gammas\n",
    "    # for each context\n",
    "    for m_it in range(n_contexts): \n",
    "        # for all cominations of the latent variables\n",
    "        for y_it in range(N_QUESTION_ANSWERS):\n",
    "            for s_it in range(N_QUESTION_ANSWERS):\n",
    "                axis_to_sum_over = tuple([0] + [i+1 for i in range(n_contexts) if i != m_it])\n",
    "                numerator = prob_latent[:,y_it].sum(axis=axis_to_sum_over)[s_it] + gamma_prior[y_it,s_it]\n",
    "                denominator = prob_latent[:, y_it].sum(axis=axis_to_sum_over).sum() + gamma_prior[y_it,:].sum()\n",
    "                gammas[m_it,y_it,s_it] = numerator / float(denominator)\n",
    "    return gammas\n",
    "\n",
    "\n",
    "def m_step_classifier(prob_latent,n_contexts,n_samples_per_obs,max_depth,n_estimators,manual_labels,y_list,X):\n",
    "    y_probs = prob_latent.sum(axis=tuple([x+2 for x in range(n_contexts)]))\n",
    "    obs = []\n",
    "    ys = []\n",
    "    for q_it in range(N_TWEETS):\n",
    "        nsamp = n_samples_per_obs\n",
    "        vals = np.random.choice(N_QUESTION_ANSWERS,size=nsamp,p=y_probs[q_it,:]).tolist()\n",
    "        ys += [y_list[m] for m in vals]\n",
    "        obs += [X[q_it,:].tolist()] * n_samples_per_obs\n",
    "    \n",
    "    \n",
    "    res = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators,n_jobs=10).fit(np.array(obs),np.array(ys))\n",
    "    classifier_predictions = res.predict_proba(X)\n",
    "    \n",
    "    # Hack for structural ablations that deteriorate. \n",
    "    y_counter = Counter(ys)\n",
    "    if len(y_counter) != 3:\n",
    "        if 'A_None' not in y_counter:\n",
    "            classifier_predictions = np.concatenate((np.zeros((len(classifier_predictions),1)),\n",
    "                                                     classifier_predictions),\n",
    "                                                    axis=1)\n",
    "    \n",
    "    return classifier_predictions, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_model(train_tweets,test_tweets, features,  y_list,\n",
    "              feature_cols, feature_cols_name, contexts_to_consider,\n",
    "              alpha_initializer, alpha_prior, gamma_initializer, gamma_prior,\n",
    "              do_manual,n_samples_per_obs,max_depth, n_estimators,use_conf_scaling,y_prior):\n",
    "    \n",
    "    context_names_info = 'all' if len(contexts_to_consider) == 6 else \" \".join(contexts_to_consider)\n",
    "    \n",
    "    params_str_info = [feature_cols_name, context_names_info, \n",
    "                       str(alpha_initializer[0]), #alpha_prior[0,0],\n",
    "                       str(gamma_initializer[0]), # gamma_prior[0,0],\n",
    "                       do_manual,max_depth,n_estimators,n_samples_per_obs,use_conf_scaling]\n",
    "    \n",
    "    # get subset of tweets for model\n",
    "    model_train_tweets = train_tweets[train_tweets.context.isin(contexts_to_consider)]\n",
    "    \n",
    "    # create test data\n",
    "    test_annotations = pd.merge(test_tweets,features,on=\"tid\")\n",
    "    testX = test_annotations[feature_cols]\n",
    "    testY = set_annotations(test_annotations)\n",
    "\n",
    "    ## Construct maps to array indices\n",
    "    annotator_map = {a : i for i,a in enumerate(set(model_train_tweets.annotator.tolist()))}\n",
    "    tid_map =  {t : i for i,t in enumerate(set(model_train_tweets.tid.tolist()))}\n",
    "    context_map =  {c : i for i,c in enumerate(set(model_train_tweets.context.tolist()))}\n",
    "\n",
    "    # Constants for iterators\n",
    "    n_contexts = len(context_map)\n",
    "    n_annotators = len(annotator_map)\n",
    "\n",
    "    # Constants/variables for algorithm\n",
    "    old_ll = -9999999.\n",
    "    new_ll = old_ll + EM_STOPPING_LL_THRESHOLD + 10\n",
    "    em_iter = 0\n",
    "\n",
    "    # Construct the X vector\n",
    "    X = [None] * N_TWEETS\n",
    "    for i, row in features.iterrows():\n",
    "        if row['tid'] in tid_map:\n",
    "            X[tid_map[row['tid']]] = row[feature_cols]\n",
    "    X = np.array(X)\n",
    "\n",
    "    # Generate initial values\n",
    "    tweet_to_context_to_annotations_map = defaultdict(lambda: defaultdict(list))\n",
    "    annotator_to_annotations_map = defaultdict(list)\n",
    "\n",
    "    tweet_to_candidate_map = {}\n",
    "    for i, row in model_train_tweets.iterrows():\n",
    "        tw_id = tid_map[row['tid']]\n",
    "        context_id = context_map[row['context']]\n",
    "        annotator_id = annotator_map[row['annotator']]\n",
    "        value = row['trinary']\n",
    "        tweet_to_candidate_map[tw_id] = row['candidate']\n",
    "        if use_conf_scaling:\n",
    "            conf = [.25,.5,1][abs(row['value'] - 3)]\n",
    "        else:\n",
    "            conf= 1\n",
    "\n",
    "        # make sure alignment is right across candidates\n",
    "        if row['candidate'] == \"Donald Trump\":\n",
    "            value *= -1\n",
    "        # make values indices ensuring 0 is the base case, 1 is clinton, 2 is trump\n",
    "        if value == -1:\n",
    "            value = 2\n",
    "\n",
    "        tweet_to_context_to_annotations_map[tw_id][context_id].append((annotator_id,value,conf))\n",
    "        annotator_to_annotations_map[annotator_id].append((tw_id,context_id,value,conf))\n",
    "\n",
    "    # Initialize Variables\n",
    "    alphas = np.array([ np.array(alpha_initializer).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))\n",
    "                        for i in range(n_annotators) ])\n",
    "\n",
    "    gammas = np.array([ np.array(gamma_initializer).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))\n",
    "                       for i in range(n_contexts) ])\n",
    "\n",
    "    initial_predictions = [None] * N_TWEETS\n",
    "    for tweet, context_anns in tweet_to_context_to_annotations_map.items():\n",
    "        options = [0] * N_QUESTION_ANSWERS\n",
    "        for context, anns in context_anns.items():\n",
    "            for a in anns:\n",
    "                options[a[1]] += 1\n",
    "        initial_predictions[tweet] = np.array(options)/float(sum(options))\n",
    "\n",
    "    classifier_predictions = np.array(initial_predictions)\n",
    "\n",
    "    # set manual annotations ... for future work on semi-supervision with gold labels\n",
    "    manual_labels = {}\n",
    "        \n",
    "    ## Run Algorithm\n",
    "    intermediate_results = []\n",
    "    while (new_ll-old_ll > EM_STOPPING_LL_THRESHOLD):\n",
    "        # E step\n",
    "        prob_latent = e_step(classifier_predictions,alphas,gammas,y_prior,tweet_to_context_to_annotations_map,n_contexts)\n",
    "\n",
    "        # M step alpha\n",
    "        alphas = m_step_alpha(prob_latent,annotator_to_annotations_map,n_contexts,n_annotators,alpha_prior)\n",
    "\n",
    "        # M step gamma\n",
    "        gammas = m_step_gamma(prob_latent,n_contexts,gamma_prior)\n",
    "\n",
    "        classifier_predictions, model = m_step_classifier(prob_latent,n_contexts,n_samples_per_obs,\n",
    "                                                          max_depth,n_estimators,manual_labels,y_list,X)\n",
    "\n",
    "        old_ll = new_ll\n",
    "        new_ll = compute_loglikelihood(alphas,gammas,classifier_predictions,\n",
    "                                       tweet_to_context_to_annotations_map,n_contexts)\n",
    "        em_iter += 1\n",
    "        evals = get_evaluations(testY,testX, model)\n",
    "        intermediate_results.append([em_iter,evals]+params_str_info+\n",
    "                                    [prob_latent.sum(axis=tuple([x+2 for x in range(n_contexts)]))])\n",
    "        print evals['f1_avg'], new_ll\n",
    "\n",
    "    return (params_str_info+[em_iter,evals.values(),model], \n",
    "            intermediate_results, gammas, alphas, classifier_predictions,tid_map,context_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_func(x):\n",
    "    return run_model(train_tweets=train_tweets, test_tweets=test_tweets, features=features,y_list=y_list,**x)\n",
    "\n",
    "N_TWEETS = len(train_tweets.tid.unique())\n",
    "N_QUESTION_ANSWERS = 3\n",
    "EM_STOPPING_LL_THRESHOLD = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in validation tweets\n",
    "validation_tweets = pd.read_csv(\"data/validation_tweets.tsv\",dtype={\"tid\":\"str\"})\n",
    "validation_tweets = validation_tweets.rename(columns={\"FINAL_ANNOTATION\" : \"final annotation\"})\n",
    "validation_tweets['has_link'] = validation_tweets.tweet_text.apply(lambda x: '{{link}}' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318, 11)\n"
     ]
    }
   ],
   "source": [
    "# create user features for validation tweets\n",
    "uids_to_featurize = validation_tweets.uid.unique().tolist() \n",
    "user_to_tid = {}\n",
    "for i, row in validation_tweets.iterrows():\n",
    "    user_to_tid[row['uid']] = row['tid']\n",
    "user_validation_features = get_user_features(uids_to_featurize,user_to_tid,validation_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create tweet features for validation tweets\n",
    "validation_tweets.loc[validation_tweets.candidate_interaction == \"NONE\",\n",
    "                                                        \"candidate_interaction\"] = \"No Mention of Target\"\n",
    "validation_tweets.loc[validation_tweets.candidate_interaction == \"TextMention\",\n",
    "                                                        \"candidate_interaction\"] = \"Plaintext Mention\"\n",
    "\n",
    "\n",
    "(validation_tweet_features,\n",
    " dictionary_tweet) = get_tweet_features(validation_tweets,dictionary_tweet,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_validation_features['tid'] = user_validation_features.tid.astype(\"str\")\n",
    "validation_tweet_features['tid'] = validation_tweet_features.tid.astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_features = pd.merge(validation_tweet_features,user_validation_features,on=\"tid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features['pol_Independent'] = 0\n",
    "features['pol_na'] = 0\n",
    "validation_tweets = validation_tweets.drop(\"has_link\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_w_validation = pd.concat((features,validation_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poltweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kennyjoseph/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000 0.84407484 0.55944056]\n",
      "prevtweet\n",
      "[0.00000000 0.84453782 0.58108108]\n",
      "polparty\n",
      "[0.00000000 0.83368421 0.53691275]\n",
      "partialuser\n",
      "[0.00000000 0.84188912 0.52554745]\n",
      "fulluser\n",
      "[0.00000000 0.81799591 0.42962963]\n",
      "none\n",
      "[0.00000000 0.82258065 0.39682540]\n",
      "All\n",
      "[0.00000000 0.83966245 0.57333333]\n"
     ]
    }
   ],
   "source": [
    "# Run the baseline prediction models\n",
    "val_params_set = []\n",
    "for context in train_tweets.context.unique().tolist() + ['All']:\n",
    "    val_params_set.append({\"context\":context})\n",
    "\n",
    "def run_func_majority_vote_validation(x):\n",
    "    return run_majority_vote_models(train_tweets=train_tweets,\n",
    "                                    test_tweets = validation_tweets,\n",
    "                                    features=features_w_validation,\n",
    "                                    feature_cols=feature_names,\n",
    "                                    feature_cols_type=\"final_feature_set\",\n",
    "                                    do_sampling=False,\n",
    "                                    n_estimators=3000,\n",
    "                                    add_manual=False,\n",
    "                                    max_depth=30,\n",
    "                                    n_to_sample=0,\n",
    "                                    class_weights=\"OUR_AUTO\",\n",
    "                                     **x)\n",
    "\n",
    "np.random.seed(0)\n",
    "modal_prediction_results_validation = []\n",
    "for param in val_params_set:\n",
    "    modal_prediction_results_validation.append(run_func_majority_vote_validation(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ll</th>\n",
       "      <th>f1_clint</th>\n",
       "      <th>f1_avg</th>\n",
       "      <th>f1_trump</th>\n",
       "      <th>context</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>do_sampling</th>\n",
       "      <th>manual</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>weights</th>\n",
       "      <th>n_none</th>\n",
       "      <th>n_trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650287</td>\n",
       "      <td>0.844538</td>\n",
       "      <td>0.712809</td>\n",
       "      <td>0.581081</td>\n",
       "      <td>prevtweet</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.669902912621_0.101694915254</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.622822</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.706498</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>All</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.614243323442_0.136363636364</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613064</td>\n",
       "      <td>0.844075</td>\n",
       "      <td>0.701758</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>poltweet</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.570247933884_0.193548387097</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626660</td>\n",
       "      <td>0.833684</td>\n",
       "      <td>0.685298</td>\n",
       "      <td>0.536913</td>\n",
       "      <td>polparty</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.583098591549_0.255319148936</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711638</td>\n",
       "      <td>0.841889</td>\n",
       "      <td>0.683718</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>partialuser</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.726315789474_0.075</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.693789</td>\n",
       "      <td>0.817996</td>\n",
       "      <td>0.623813</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>fulluser</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.704081632653_0.0821917808219</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.724261</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.609703</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>none</td>\n",
       "      <td>final_feature_set</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.734042553191_0.0685714285714</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ll  f1_clint    f1_avg  f1_trump      context        feature_set  \\\n",
       "1  0.650287  0.844538  0.712809  0.581081    prevtweet  final_feature_set   \n",
       "6  0.622822  0.839662  0.706498  0.573333          All  final_feature_set   \n",
       "0  0.613064  0.844075  0.701758  0.559441     poltweet  final_feature_set   \n",
       "2  0.626660  0.833684  0.685298  0.536913     polparty  final_feature_set   \n",
       "3  0.711638  0.841889  0.683718  0.525547  partialuser  final_feature_set   \n",
       "4  0.693789  0.817996  0.623813  0.429630     fulluser  final_feature_set   \n",
       "5  0.724261  0.822581  0.609703  0.396825         none  final_feature_set   \n",
       "\n",
       "  do_sampling manual  max_depth  n_estimators                         weights  \\\n",
       "1       False  False         30          3000   0.669902912621_0.101694915254   \n",
       "6       False  False         30          3000   0.614243323442_0.136363636364   \n",
       "0       False  False         30          3000   0.570247933884_0.193548387097   \n",
       "2       False  False         30          3000   0.583098591549_0.255319148936   \n",
       "3       False  False         30          3000            0.726315789474_0.075   \n",
       "4       False  False         30          3000  0.704081632653_0.0821917808219   \n",
       "5       False  False         30          3000  0.734042553191_0.0685714285714   \n",
       "\n",
       "   n_none  n_trump  \n",
       "1       0       49  \n",
       "6       0       51  \n",
       "0       0       44  \n",
       "2       0       50  \n",
       "3       0       38  \n",
       "4       0       36  \n",
       "5       2       27  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_modal_results_df = pd.DataFrame([[x[1]]+x[3:6] + x[6:-3] + [x[-2]['A_None'],x[-2]['Trump']] \n",
    "                                     for x in modal_prediction_results_validation],\n",
    "                                columns= ['ll','f1_clint','f1_avg','f1_trump',\n",
    "                                          'context','feature_set','do_sampling','manual',\n",
    "                                          'max_depth','n_estimators','weights','n_none','n_trump'])\n",
    "val_modal_results_df.sort_values(\"f1_avg\",ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_init = [.98,0.01,0.01,0.01,.98,0.01,0.01,0.01,.98]\n",
    "gamma_init =[.4,.3,.3,.2,.75,.05,.2,.05,.75]\n",
    "alpha_prior = 0\n",
    "gamma_prior = 0\n",
    "\n",
    "ap = np.array(alpha_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))*alpha_prior\n",
    "gp = np.array(gamma_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS))*gamma_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000 0.85344828 0.65000000]\n",
      "0.751724137931 -5899.841733\n",
      "[0.00000000 0.85344828 0.65000000]\n",
      "0.751724137931 -5747.08511901\n",
      "[0.00000000 0.85097192 0.64150943]\n",
      "0.746240678104 -5681.03936085\n",
      "[0.12500000 0.85529158 0.63694268]\n",
      "0.746117125917 -5652.68152299\n",
      "[0.12500000 0.86274510 0.67080745]\n",
      "0.766776275728 -5637.98632087\n"
     ]
    }
   ],
   "source": [
    "# Full Model\n",
    "np.random.seed(0)\n",
    "model_result = run_model(train_tweets=train_tweets,\n",
    "                          test_tweets=validation_tweets, \n",
    "                          features=features_w_validation, \n",
    "                          y_list=y_list,\n",
    "                          feature_cols=feature_names,\n",
    "                          feature_cols_name=\"final_feature_set\",\n",
    "                          contexts_to_consider=['polparty','poltweet','prevtweet','none','fulluser','partialuser'],\n",
    "                          alpha_prior=ap, alpha_initializer=alpha_init,\n",
    "                          gamma_prior=gp, gamma_initializer=gamma_init,\n",
    "                          do_manual=False,\n",
    "                          n_samples_per_obs=10,\n",
    "                          max_depth=30,\n",
    "                          n_estimators=3000,\n",
    "                          use_conf_scaling=False,\n",
    "                          y_prior = [.01,.495,.495])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000 0.85161290 0.64150943]\n",
      "0.746561168594 -6060.39340612\n",
      "[0.00000000 0.85224839 0.63694268]\n",
      "0.744595534582 -5976.40273798\n",
      "[0.00000000 0.85407725 0.64556962]\n",
      "0.749823436736 -5958.71048625\n"
     ]
    }
   ],
   "source": [
    "# Model - No Context \n",
    "\n",
    "# Note the y-prior difference -> the Log-loss on these models below up if we didn't do this.\n",
    "# Because its fair to say that we could have optimized these ablations as well (they are, in a sense, \n",
    "# separate models), we chose better y-priors for them to make a more fair comparison.\n",
    "\n",
    "train_tweets_copy_all_contexts_same = train_tweets.copy()\n",
    "train_tweets_copy_all_contexts_same['context'] = 'ALL_SAME'\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "model_res_no_context = run_model(train_tweets=train_tweets_copy_all_contexts_same,\n",
    "                      test_tweets=validation_tweets, \n",
    "                      features=features_w_validation, \n",
    "                      y_list=y_list,\n",
    "                      feature_cols=feature_names,\n",
    "                      feature_cols_name=\"final_feature_set\",\n",
    "                      contexts_to_consider=[\"ALL_SAME\"],\n",
    "                      alpha_prior=np.array(alpha_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      alpha_initializer=alpha_init,\n",
    "                      gamma_prior=np.array(gamma_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      gamma_initializer=gamma_init,\n",
    "                      do_manual=False,\n",
    "                      n_samples_per_obs=10,\n",
    "                      max_depth=30,\n",
    "                      n_estimators=3000,\n",
    "                      use_conf_scaling=False,\n",
    "                      y_prior = [.1,.45,.45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000 0.84810127 0.60000000]\n",
      "0.724050632911 -498.038355669\n",
      "[0.00000000 0.85052632 0.60402685]\n",
      "0.727276580714 -453.428815318\n",
      "[0.00000000 0.85232068 0.61333333]\n",
      "0.732827004219 -423.108463813\n",
      "[0.00000000 0.85052632 0.60402685]\n",
      "0.727276580714 -413.036364162\n"
     ]
    }
   ],
   "source": [
    "# Model - One Context \n",
    "np.random.seed(0)\n",
    "\n",
    "model_res_one_context = run_model(train_tweets=train_tweets,\n",
    "                      test_tweets=validation_tweets, \n",
    "                      features=features_w_validation, \n",
    "                      y_list=y_list,\n",
    "                      feature_cols=feature_names,\n",
    "                      feature_cols_name=\"final_feature_set\",\n",
    "                      contexts_to_consider=[\"poltweet\"],\n",
    "                      alpha_prior=np.array(alpha_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      alpha_initializer=alpha_init,\n",
    "                      gamma_prior=np.array(gamma_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      gamma_initializer=gamma_init,\n",
    "                      do_manual=False,\n",
    "                      n_samples_per_obs=10,\n",
    "                      max_depth=30,\n",
    "                      n_estimators=3000,\n",
    "                      use_conf_scaling=False,\n",
    "                      y_prior = [.1,.45,.45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12500000 0.85529158 0.63694268]\n",
      "0.746117125917 -6937.37173774\n",
      "[0.11764706 0.86026201 0.67080745]\n",
      "0.765534731075 -6813.38360958\n",
      "[0.11764706 0.85217391 0.64150943]\n",
      "0.746841673503 -6763.13174349\n",
      "[0.10526316 0.85152838 0.64150943]\n",
      "0.746518909121 -6731.4186799\n",
      "[0.19047619 0.85274725 0.65000000]\n",
      "0.751373626374 -6710.66308483\n"
     ]
    }
   ],
   "source": [
    "# Model - One Annotator\n",
    "train_tweets_copy_all_annotators_same = train_tweets.copy()\n",
    "train_tweets_copy_all_annotators_same['annotator'] = 'ANNOTATOR'\n",
    "np.random.seed(0)\n",
    "\n",
    "model_res_no_ann = run_model(train_tweets=train_tweets_copy_all_annotators_same,\n",
    "                      test_tweets=validation_tweets, \n",
    "                      features=features_w_validation, \n",
    "                      y_list=y_list,\n",
    "                      feature_cols=feature_names,\n",
    "                      feature_cols_name=\"final_feature_set\",\n",
    "                      contexts_to_consider=['polparty','poltweet','prevtweet','none','fulluser','partialuser'],\n",
    "                      alpha_prior=np.array(alpha_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      alpha_initializer=alpha_init,\n",
    "                      gamma_prior=np.array(gamma_init).reshape((N_QUESTION_ANSWERS,N_QUESTION_ANSWERS)),\n",
    "                      gamma_initializer=gamma_init,\n",
    "                      do_manual=False,\n",
    "                      n_samples_per_obs=10,\n",
    "                      max_depth=30,\n",
    "                      n_estimators=3000,\n",
    "                      use_conf_scaling=False,\n",
    "                      y_prior = [.1,.45,.45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F1 Predictions, write out\n",
    "val_annotations = set_annotations(validation_tweets)\n",
    "\n",
    "modal = [zip(val_annotations,x[2], [x[6]]*len(x[2])) for x in modal_prediction_results_validation]\n",
    "non_modal = [zip(val_annotations,x[0][-2][2], [y]*len(x[0][-2][2])) \n",
    "                 for y,x in [(\"Full\",model_result),\n",
    "                             (\"Pol Tweet Context\",model_res_one_context),\n",
    "                             (\"One Context\",model_res_no_context),\n",
    "                             (\"One Annotator\",model_res_no_ann)]]\n",
    "results_df = pd.DataFrame([y for x in modal + non_modal for y in x],columns=['actual','predicted','model'])\n",
    "results_df.to_csv(\"results/model_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Log Loss Predictions, write out\n",
    "val_annotations = set_annotations(validation_tweets)\n",
    "\n",
    "modal = [zip(val_annotations,x[0][:,1],x[0][:,2],[x[6]]*len(x[0])) for x in modal_prediction_results_validation]\n",
    "non_modal = [zip(val_annotations,x[0][-2][0][:,1],x[0][-2][0][:,2], [y]*len(x[0][-2][0])) \n",
    "                 for y,x in [(\"Full\",model_result),\n",
    "                             (\"Pol Tweet Context\",model_res_one_context),\n",
    "                             (\"One Context\",model_res_no_context),\n",
    "                             (\"One Annotator\",model_res_no_ann)]]\n",
    "results_df = pd.DataFrame([y for x in modal + non_modal for y in x],columns=['actual','clinton_prob','trump_prob','model'])\n",
    "results_df.to_csv(\"results/model_results_ll.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none, A_None, A_None, 0.999998082164\n",
      "none, A_None, Clinton, 1.91781604772e-06\n",
      "none, A_None, Trump, 2.01110368158e-11\n",
      "none, Clinton, A_None, 0.23590827035\n",
      "none, Clinton, Clinton, 0.761269289358\n",
      "none, Clinton, Trump, 0.00282244029141\n",
      "none, Trump, A_None, 0.291378123205\n",
      "none, Trump, Clinton, 0.00807223635941\n",
      "none, Trump, Trump, 0.700549640435\n",
      "partialuser, A_None, A_None, 0.99528868331\n",
      "partialuser, A_None, Clinton, 0.00471126178026\n",
      "partialuser, A_None, Trump, 5.49097049215e-08\n",
      "partialuser, Clinton, A_None, 0.220455391771\n",
      "partialuser, Clinton, Clinton, 0.770076540135\n",
      "partialuser, Clinton, Trump, 0.0094680680947\n",
      "partialuser, Trump, A_None, 0.202557451929\n",
      "partialuser, Trump, Clinton, 0.0171579614647\n",
      "partialuser, Trump, Trump, 0.780284586606\n",
      "fulluser, A_None, A_None, 0.972443995475\n",
      "fulluser, A_None, Clinton, 3.12456443242e-07\n",
      "fulluser, A_None, Trump, 0.0275556920689\n",
      "fulluser, Clinton, A_None, 0.206686465974\n",
      "fulluser, Clinton, Clinton, 0.787116780343\n",
      "fulluser, Clinton, Trump, 0.00619675368298\n",
      "fulluser, Trump, A_None, 0.213043620992\n",
      "fulluser, Trump, Clinton, 0.00818850626399\n",
      "fulluser, Trump, Trump, 0.778767872744\n",
      "prevtweet, A_None, A_None, 0.993620766275\n",
      "prevtweet, A_None, Clinton, 4.41810620943e-06\n",
      "prevtweet, A_None, Trump, 0.00637481561924\n",
      "prevtweet, Clinton, A_None, 0.12872697606\n",
      "prevtweet, Clinton, Clinton, 0.8635405785\n",
      "prevtweet, Clinton, Trump, 0.00773244543967\n",
      "prevtweet, Trump, A_None, 0.0975471389731\n",
      "prevtweet, Trump, Clinton, 0.0228560319639\n",
      "prevtweet, Trump, Trump, 0.879596829063\n",
      "poltweet, A_None, A_None, 0.874698633165\n",
      "poltweet, A_None, Clinton, 0.086889647177\n",
      "poltweet, A_None, Trump, 0.0384117196575\n",
      "poltweet, Clinton, A_None, 0.0292889109529\n",
      "poltweet, Clinton, Clinton, 0.964958731384\n",
      "poltweet, Clinton, Trump, 0.00575235766322\n",
      "poltweet, Trump, A_None, 0.035970333689\n",
      "poltweet, Trump, Clinton, 0.0973796574699\n",
      "poltweet, Trump, Trump, 0.866650008841\n",
      "polparty, A_None, A_None, 0.289679218454\n",
      "polparty, A_None, Clinton, 0.340436054541\n",
      "polparty, A_None, Trump, 0.369884727005\n",
      "polparty, Clinton, A_None, 0.0214792776068\n",
      "polparty, Clinton, Clinton, 0.934047179633\n",
      "polparty, Clinton, Trump, 0.0444735427599\n",
      "polparty, Trump, A_None, 0.0169605900072\n",
      "polparty, Trump, Clinton, 0.1144597228\n",
      "polparty, Trump, Trump, 0.868579687193\n"
     ]
    }
   ],
   "source": [
    "# gamma\n",
    "for k, v in model_result[-1].items():\n",
    "    r = [(k,y_list[i], y_list[j], model_result[-5][v][i,j]) for i in range(3) for j in range(3)]\n",
    "    for x in r:\n",
    "        print \", \".join([str(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
